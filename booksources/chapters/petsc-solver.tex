% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2012-9
%%%%
%%%% petsc-solver.tex : linear system solvers
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Probably the most important activity in PETSc is solving a linear
system. This is done through a solver object: an object of the class
\indexpetscdef{KSP}. (This stands for Krylov SPace solver.) The solution routine
\lstinline{KSPSolve} takes a matrix and a right-hand-side and gives a
solution; however, before you can call this some amount of setup is needed.

There two very different ways of solving a
linear system: through a direct method, essentially a variant of
Gaussian elimination; or through an iterative method that makes
successive approximations to the solution. In PETSc there are only
iterative methods. We will show how to achieve direct methods later.
The default linear system solver in PETSc is fully parallel, and will
work on many linear systems, but there are many settings and
customizations to tailor the solver to your specific problem.

\Level 0 {KSP: linear system solvers}
\label{sec:petsc-ksp}

\Level 1 {Math background}

Many scientific applications boil down to the solution of a system of
linear equations at some point:
\[ ?_x\colon Ax=b \]
The elementary textbook way of solving this is through an
\indexterm{LU factorization},
also known as \indexterm{Gaussian elimination}:
\[ LU\leftarrow A,\qquad Lz=b,\qquad Ux=z. \]
While PETSc has support for this, its basic design is geared towards
so-called iterative solution methods.
Instead of directly computing
the solution to the system, they compute a sequence of approximations
that, with luck, converges to the true solution:

\begin{quote}
  \begin{tabbing}
    while \=not converged\\
    \> $x_{i+1}\leftarrow f(x_i)$
  \end{tabbing}
\end{quote}

The interesting thing about iterative methods is that the iterative step
only involved the \indexterm{matrix-vector product}:

\begin{quote}
  \begin{tabbing}
    while \=not converged\\
    \> $r_i = Ax_i-b$\\
    \> $x_{i+1}\leftarrow f(r_i)$
  \end{tabbing}
\end{quote}

This \indexterm{residual} is also crucial in determining whether to stop the iteration:
since we (clearly) can not measure the distance to the true solution, we use
the size of the residual as a proxy measurement.

The remaining point to know is that iterative methods feature a \indexterm{preconditioner}.
Mathematically this is equivalent to transforming the linear system to
\[ M\inv Ax=M\inv b \]
so conceivably we could iterate on the preconditioned matrix and right-hand side.
However, in practice we apply the preconditioner in each iteration:

\begin{quote}
  \begin{tabbing}
    while \=not converged\\
    \> $r_i = Ax_i-b$\\
    \> $z_i = M\inv r_i$\\
    \> $x_{i+1}\leftarrow f(z_i)$
  \end{tabbing}
\end{quote}

In this schematic presentation we have left the nature of the $f()$ update
function unspecified. Here, many possibilities exist; the primary
choice here if of the iterative method type, such as `conjugate gradients',
`generalized minimum residual', or `bi-conjugate gradients stabilized'.

\Level 1 {Solver objects}

First we create a KSP object, which contains the coefficient matrix,
and various parameters such as the desired accuracy,
as well as method specific parameters:
%
\indexpetscref{KSPCreate}.

After this, the basic scenario is:
\begin{lstlisting}
Vec rhs,sol;
KSP solver;
KSPSetOperators(solver,A,A);
KSPSolve(solver,rhs,sol);
\end{lstlisting}
using various default settings. The vectors and the matrix have to be
conformly partitioned.

Since neither
solution nor solution speed is guaranteed, an iterative solver is
subject to some tolerances:
\begin{itemize}
\item a relative tolerance for when the residual has been reduced
  enough;
\item an absolute tolerance for when the residual is objectively
  small;
\item a divergence tolerance that stops the iteration if the residual
  grows by too much; and
\item a bound on the number of iterations, regardless any progress the
  process may still be making.
\end{itemize}

These tolerances are set with \indexpetscref{KSPSetTolerances}.

\Level 1 {Why did my solver stop? Did it work?}
\label{sec:ksp-reason}

On return of the \indexmpishow{KSPSolve} routine there is no guarantee
that the system was successfully solved.
Therefore, you need to invoke
\indexpetscref{KSPGetConvergedReason}
to get a \indexpetscshow{KSPConvergedReason} parameter that indicates
what state the solver stopped in:
\begin{itemize}
\item The iteration can have successfully converged; this corresponds
  to \lstinline{reason}$>0$;
\item the iteration can have diverged, or otherwise failed: \lstinline{reason}$<0$;
\item or the iteration may have stopped at the maximum number of
  iterations while still making progress; \lstinline{reason}$=0$.
\end{itemize}
For more detail, \indexpetscshow{KSPReasonView} can print out the
reason in readable form; for instance
\begin{lstlisting}
KSPReasonView(solver,PETSC_VIEWER_STDOUT_WORLD);
\end{lstlisting}
(This can also be activated with the \n{-ksp_converged_reason}
commandline option.)

In case of successful convergence, you can use \indexpetscshow{KSPGetIterationNumber}
to report how many
iterations were taken.

The following snippet analyzes the status of a \lstinline{KSP} object
that has stopped iterating:
%
\cverbatimsnippet[code/petsc/c]{petscreasonreport}

\Level 1 {Choice of iterator}

There are many iterative methods, and it takes a few function calls to fully specify them:

\petscRoutineRef{KSPSetType}

Here are some values:
\begin{itemize}
\item \lstinline{KSPCG}: only for symmetric positive definite systems.
\item \lstinline{KSPGMRES}: a minimization method that works fairly
  generally; has high memory demands.
\item \lstinline{KSPBCGS}: a quasi-minimization method; uses less memory than GMRES.
\end{itemize}

\Level 1 {Preconditioners}

Another part of an iterative solver is the
\indextermdef{preconditioner}; think of it as an approximation to the inverse.

\begin{lstlisting}
PC prec;
KSPGetPC(solver,&prec);
PCSetType(prec,PCILU);
\end{lstlisting}

Some popular types:
\begin{itemize}
\item \lstinline{PCILU}: an approximate factorization
\item \lstinline{PCSPAI}: an approximate inverse
\item \lstinline{PCASM}: additive Schwarz method
\end{itemize}

\Level 0 {Direct solvers}

PETSc has some support for direct solvers, that is, variants of LU
decomposition. In a sequential context, the \lstinline{PCLU}
preconditioner can be use for this: a direct solver is equivalent to
an iterative method that stops after one preconditioner
application. This can be forced by specifying a KSP type of
\lstinline{KSPPREONLY}.

Distributed direct solvers are more complicated. PETSc does not have
this implemented in its basic code, but it becomes available by
configuring PETSc with the
\indexterm{scalapack} library.

You need to specify which package provides the LU factorization:

\begin{lstlisting}
PCFactorSetMatSolverType(pc, <solvertype> )
\end{lstlisting}

where solvertype can be mumps, superlu, umfpack, or a number of
others. Note that availability of these packages depends on how PETSc
was installed on your system.

\Level 0 {Control through command line options}

From the above you may get the impression that there are lots of calls
to be made to set up a PETSc linear system and solver. And what if you
want to experiment with different solvers, does that mean that you
have to edit a whole bunch of code? Fortunately, there is an easier
way to do things. If you call the routine
%
\indexpetscref{KSPSetFromOptions}
with the \lstinline{solver} as argument,
%
PETSc will look at your command line options and take those into
account in defining the solver. Thus, you can either omit setting
options in your source code, or use this as a way of quickly
experimenting with different possibilities. Example:

\begin{verbatim}
myprogram -ksp_type gmres -ksp_type_gmres_restart 20 -ksp_max_it 200 \
  -pc_type ilu -pc_type_ilu_levels 3
\end{verbatim}

