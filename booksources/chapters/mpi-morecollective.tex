% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2012-8
%%%%
%%%% mpi-morecollective.tex : obscure stuff
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Level 0 {MPI Operators}
\index{operator|(}

MPI \emph{operators} are used in reduction operators. Most common
operators, such as sum or maximum, have been built into the MPI
library, but it is possible to define new operators.

\Level 1 {Pre-defined operators}

\emph{Pre-defined operators}\index{operator!predefined}
are listed in section~\ref{sec:operator-list}.

\Level 1 {User-defined operators}

In addition to predefined operators, MPI has the possibility of
\emph{user-defined operators}\index{operator!user-defined}
to use in a reduction or scan operation.

\mpiRoutineRef{MPI_Op_create}

The function needs to have the following prototype:

\begin{verbatim}
typedef void MPI_User_function
    ( void *invec, void *inoutvec, int *len, 
      MPI_Datatype *datatype); 

FUNCTION USER_FUNCTION( INVEC(*), INOUTVEC(*), LEN, TYPE) 
<type> INVEC(LEN), INOUTVEC(LEN) 
INTEGER LEN, TYPE 
\end{verbatim}

The function has an array length argument~\n{len}, to allow for
pointwise reduction on a a whole array at once. The \n{inoutvec} array
contains partially reduced results, and is typically overwritten by
the function.

For example, here is an operator for finding the smallest non-zero
number in an array of nonnegative integers:
%
\verbatimsnippet{mpirwz}

You can query the commutativity of an operator:
%
\mpiRoutineRef{MPI_Op_commutative}

A created \n{MPI_Op} can be freed again:
%
\begin{lstlisting}
int MPI_Op_free(MPI_Op *op)
\end{lstlisting}
%
This sets the operator to \indexmpishow{MPI_OP_NULL}.

\Level 1 {Local reduction}

The application of an \n{MPI_OP} can be performed with the routine
\indexmpishow{MPI_Reduce_local}. Using this routine and some
send/receive scheme you can build your own global reductions. Note
that this routine does not take a communicator because it is purely local.

\mpiRoutineRef{MPI_Reduce_local}

\index{operator|)}

\Level 0 {Non-blocking collectives}
\label{sec:mpi3collect}

Above you have seen how the `Isend' and `Irecv' routines can overlap communication
with computation. This is not possible with the collectives you have seen so far:
they act like blocking sends or receives.
However, there are also \indextermsub{non-blocking}{collectives}.
These have roughly the same calling sequence as their blocking counterparts,
except that they output an \indexmpishow{MPI_Request}. You
can then use an \indexmpishow{MPI_Wait} call to make sure the collective
has completed.

Such operations can be used to increase efficiency.
For instance, computing
\[ y \leftarrow Ax + (x^tx)y \]
involves a matrix-vector product, which is dominated by computation
in the \indextermsub{sparse}{matrix} case, and an inner product which is 
typically dominated by the communication cost. You would code this as
\begin{lstlisting}
MPI_Iallreduce( .... x ..., &request);
// compute the matrix vector product
MPI_Wait(request);
// do the addition
\end{lstlisting}

This can also be used for 3D FFT operations~\cite{Hoefler:case-for-nbc}.
Occasionally, a non-blocking collective can be used for non-obvious purposes,
such as the \indexmpishow{MPI_Ibarrier} in~\cite{Hoefler:2010:SCP}.

The same calling sequence as the blocking counterpart, except for the addition
of an \indexmpishow{MPI_Request} parameter. For instance 
\indexmpishow{MPI_Ibcast}:
\begin{lstlisting}
int MPI_Ibcast(
  void *buffer, int count, MPI_Datatype datatype,
  int root, MPI_Comm comm, 
  MPI_Request *request)
\end{lstlisting}

\mpiRoutineRef{MPI_Iallreduce}

\mpiRoutineRef{MPI_Iallgather}

\Level 0 {Performance of collectives}

It is easy to visualize a broadcast as in figure~\ref{fig:bcast-simple}:
see figure~\ref{fig:bcast-simple}.
\begin{figure}[ht]
  \includegraphics[scale=.08]{graphics/bcast-simple}
  \caption{A simple broadcast}
  \label{fig:bcast-simple}
\end{figure}
the root sends all of its data directly to every other process.
While this describes the semantics of the operation, in practice
the implementation works quite differently.

The time that a message takes can simply be modeled as
\[ \alpha +\beta n, \]
where $\alpha$~is the \indexterm{latency}, a~one time
delay from establishing the communication between two processes,
and $\beta$~is the time-per-byte, or the inverse of the \indexterm{bandwidth},
and $n$~the number of bytes sent.

Under the assumption that
a processor can only send one message at a time,
the broadcast in
figure~\ref{fig:bcast-simple} would take a time proportional to the
number of processors.

\begin{exercise}
  \label{ex:latencylinear}
  What is the total time required for a broadcast involving $p$
  processes?
  Give $\alpha$ and $\beta$ terms separately.
\end{exercise}

One way to ameliorate that is to structure the
broadcast in a tree-like fashion.
\begin{figure}[ht]
  \includegraphics[scale=.1]{graphics/bcast-tree}
  \caption{A tree-based broadcast}
  \label{fig:bcast-tree}
\end{figure}
This is depicted in figure~\ref{fig:bcast-tree}.

\begin{exercise}
  \label{ex:latencylog}
  How does the
  communication time now depend on the number of processors, again
  $\alpha$ and $\beta$ terms separately.

  What would be a lower bound on the $\alpha,\beta$ terms?
\end{exercise}

The theory
of the complexity of collectives is described in more detail in
\HPSCref{sec:collective}; see also~\cite{Chan2007Collective}.

\Level 0 {Collectives and synchronization}

Collectives, other than a barrier, have a synchronizing effect between processors.
For instance, in
\begin{lstlisting}
MPI_Bcast( ....data... root);
MPI_Send(....);
\end{lstlisting}
the send operations on all processors will occur after the root executes
the broadcast. 
\begin{figure}[ht]
  \includegraphics[scale=.35]{graphics/reduce-two-node}
  \caption{Trace of a reduction operation between two dual-socket 12-core nodes}
  \label{fig:trace-reduce}
\end{figure}
Conversely, in a reduce operation the root may have to wait for 
other processors. This is illustrated in figure~\ref{fig:trace-reduce}, which 
gives a TAU trace of
a reduction operation on two nodes, with two six-core sockets (processors) each.
We see that\footnote
{This uses mvapich version 1.6; in version 1.9 the implementation of an on-node reduction
has changed to simulate shared memory.}:
\begin{itemize}
\item In each socket, the reduction is a linear accumulation;
\item on each node, cores zero and six then combine their result;
\item after which the final accumulation is done through the network.
\end{itemize}
We also see that the two nodes are not perfectly in sync, which is normal for MPI
applications. As a result, core~0 on the first node will sit idle until it receives the partial
result from core~12, which is on the second node.

\begin{figure}[p]
  \footnotesize
  \leftskip=\unitindent
  \rightskip=\unitindent
Code:
{\tiny
\begin{lstlisting}
switch(rank) { 
    case 0: 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        break; 
    case 1: 
        MPI_Recv(buf2, count, type, MPI_ANY_SOURCE, tag, comm, status); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Recv(buf2, count, type, MPI_ANY_SOURCE, tag, comm, status); 
        break; 
    case 2: 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        break; 
}
\end{lstlisting}
}
The most logical execution is:\par\medskip

\includegraphics[scale=.35]{backintime1}

However, this ordering is allowed too:\par\medskip

\includegraphics[scale=.35]{backintime2}

Which looks from a distance like:\par\medskip

\includegraphics[scale=.35]{backintime3}

In other words, one of the messages seems to go `back in time'.

  \caption{Possible temporal orderings of send and collective calls}
  \label{fig:backintime}
\end{figure}

While collectives synchronize in a loose sense, it is not possible to
make any statements about events before and after the collectives
between processors:
\begin{lstlisting}
...event 1...
MPI_Bcast(....);
...event 2....
\end{lstlisting}
Consider a specific scenario:
\begin{lstlisting}
switch(rank) { 
    case 0: 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        break; 
    case 1: 
        MPI_Recv(buf2, count, type, MPI_ANY_SOURCE, tag, comm, status); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        MPI_Recv(buf2, count, type, MPI_ANY_SOURCE, tag, comm, status); 
        break; 
    case 2: 
        MPI_Send(buf2, count, type, 1, tag, comm); 
        MPI_Bcast(buf1, count, type, 0, comm); 
        break; 
}
\end{lstlisting}
Note the \n{MPI_ANY_SOURCE} parameter in the receive calls on processor~1.
One obvious execution of this would be:
\begin{enumerate}
\item The send from~2 is caught by processor~1;
\item Everyone executes the broadcast;
\item The send from~0 is caught by processor~1.
\end{enumerate}
However, it is equally possible to have this execution:
\begin{enumerate}
\item Processor~0 starts its broadcast, then executes the send;
\item Processor~1's receive catches the data from~0, then it executes
  its part of the broadcast;
\item Processor~1 catches the data sent by~2, and finally processor~2
  does its part of the broadcast.
\end{enumerate}

This is illustrated in figure~\ref{fig:backintime}.
