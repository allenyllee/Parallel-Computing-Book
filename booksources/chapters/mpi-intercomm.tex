% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2012-9
%%%%
%%%% mpi-intercomm.tex : about splitting communicators
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Level 0 {Inter-communicators}

If two disjoint communicators exist, it may be necessary to
communicate between them. This can of course be done by creating a new
communicator that overlaps them, but this would be complicated: since
the `inter' communication happens in the overlap communicator, you
have to translate its ordering into those of the two worker
communicators. It would be easier to express messages directly in
terms of those communicators, and this can be done with
`inter-communicators'.

\mpiRoutineRef{MPI_Intercomm_create}

After this, the intercommunicator can be used in collectives such as
a broadcast.

Example:
\begin{lstlisting}
MPI_Bcast (buff, count, dtype, root, comm, ierr)
\end{lstlisting}
\begin{itemize}
\item In group~A, the root process passes \indexmpishow{MPI_ROOT} as
  `root' value; all others use \indexmpishow{MPI_PROC_NULL}.
\item In group~B, all processes use a `root' value that is the
  rank of the root process in the root group.
\end{itemize}
Gather and scatter behave similarly; the allgather is different: all
send buffers of group~A are concatenated in rank order, and places on
all processes of group~B.

Inter-communicators can be used if two groups of process work
asynchronously with respect to each other; another application is
fault tolerance (section~\ref{mpi:tolerant}).

% this list stolen from CI Tutor: rewrite
Some rules on intercommunicators:
\begin{itemize}
\item The local and remote groups must be disjoint (a given process
  cannot be in both).
\item
  Only point-to-point communication is allowed between the two
  intracommunicators.% [MPI_SEND() and its variants and MPI_RECV()]
\item 
  Only blocking process-to-process communication is allowed.
\item 
  Collective communication calls cannot be made in an
  intercommunicator (still allowed in the local and remote
  intracommunicators internally). This rule naturally follows from the
  previous rule.
\item 
  The syntax for \indexmpishow{MPI_Send} and \indexmpishow{MPI_Recv}
  is the same for an intercommunication as a `normal'
  intracommunication. Of course, the communicator specified must be
  the name of the intercommunicator. Most importantly, the ranks used
  must be the relative ranks in the local and remote
  intracommunicators.

  This rule illustrates a syntax advantage in using an
  intercommunicator. Processes are indentified by their `natural'
  local and remote intracommunicator ranks. Not by the `global'
  ranks they are assigned in \indexmpishow{MPI_COMM_WORLD}.  Virtual topologies
  cannot be created with an intercommunicator. To set up virtual
  topologies, first transform the intercommunicator to an
  intracommunicator with the function
  \indexmpishow{MPI_Intercomm_merge}
\end{itemize}

Create an intracommuncator from an intercommunicator:
\mpiRoutineRef{MPI_Intercomm_merge}
