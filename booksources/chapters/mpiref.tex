% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2012-7
%%%%
%%%% mpiref.tex : MPI reference
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section gives reference information and illustrative examples
of the use of MPI. While the code snippets given here should be enough,
full programs can be found in the repository for this book
\url{https://bitbucket.org/VictorEijkhout/parallel-computing-book}.

\Level 0 {Communicators}

\Level 1 {Process topologies}
\label{sec:ref:topology}

\Level 2 {Cartesian grid topology}
\label{sec:ref:cartesian}

\Level 0 {Leftover topics}

\Level 1 {MPI constants}
\index{MPI!constants|(}

MPI has a number of built-in \emph{constants}. These do not all behave
the same.
\begin{itemize}
\item Some are \emph{compile-time}\index{MPI!constants!compile-time}
  constants. Examples are \indexmpishow{MPI_VERSION} and
  \indexmpishow{MPI_MAX_PROCESSOR_NAME}. Thus, they can be used in
  array size declarations, even before \indexmpishow{MPI_Init}.
\item Some \emph{link-time}\index{MPI!constants!link-time}
  constants get their value by MPI initialization, such as
  \indexmpishow{MPI_COMM_WORLD}. Such symbols, which include all
  predefined handles, can be used in initialization expressions.
\item Some link-time symbols can not be used in initialization
  expressions, such as \indexmpishow{MPI_BOTTOM} and \indexmpishow{MPI_STATUS_IGNORE}.
\end{itemize}

For symbols, the binary realization is not defined. For instance,
\indexmpishow{MPI_COMM_WORLD} is of type \indexmpishow{MPI_Comm}, but
the implementation of that type is not specified.

See Annex~A of the 3.1 standard for full lists.

The following are the compile-time constants:
\begin{verbatim}
MPI_MAX_PROCESSOR_NAME
MPI_MAX_LIBRARY_VERSION_STRING
MPI_MAX_ERROR_STRING
MPI_MAX_DATAREP_STRING
MPI_MAX_INFO_KEY
MPI_MAX_INFO_VAL
MPI_MAX_OBJECT_NAME
MPI_MAX_PORT_NAME
MPI_VERSION
MPI_SUBVERSION
MPI_STATUS_SIZE (Fortran only)
MPI_ADDRESS_KIND (Fortran only)
MPI_COUNT_KIND (Fortran only)
MPI_INTEGER_KIND (Fortran only)
MPI_OFFSET_KIND (Fortran only)
MPI_SUBARRAYS_SUPPORTED (Fortran only)
MPI_ASYNC_PROTECTS_NONBLOCKING (Fortran only)
\end{verbatim}

The following are the link-time constants:
\begin{verbatim}
MPI_BOTTOM
MPI_STATUS_IGNORE
MPI_STATUSES_IGNORE
MPI_ERRCODES_IGNORE
MPI_IN_PLACE
MPI_ARGV_NULL
MPI_ARGVS_NULL
MPI_UNWEIGHTED
MPI_WEIGHTS_EMPTY
\end{verbatim}

Assorted constants:
\begin{verbatim}
C type: const int (or unnamed enum)
Fortran type: INTEGER

MPI_PROC_NULL
MPI_ANY_SOURCE
MPI_ANY_TAG
MPI_UNDEFINED
MPI_BSEND_OVERHEAD
MPI_KEYVAL_INVALID                
MPI_LOCK_EXCLUSIVE
MPI_LOCK_SHARED
MPI_ROOT
\end{verbatim}

(This section was inspired by
\url{http://blogs.cisco.com/performance/mpi-outside-of-c-and-fortran}.)

\index{MPI!constants|)}

\Level 1 {32-bit size issues}

The \n{size} parameter in MPI routines is defined as an \n{int},
meaning that it is limited to 32-bit quantities.  There are ways
around this, such as sending a number of
\indexmpishow{MPI_Type_contiguous} blocks that add up to more than~$2^{31}$.

\Level 1 {Fortran issues}
\label{sec:ref:mpi-fortran}
\index{MPI!Fortran issues|(}

\Level 2 {Data types}

The equivalent of \indexmpishowsub{MPI_Aint}{in Fortran} is
\begin{verbatim}
integer(kind=MPI_ADDRESS_KIND) :: winsize
\end{verbatim}

\Level 2 {Type issues}

Fortran90 is a strongly typed language, so it is not possible to pass
argument by reference to their address, as C/C++ do with the \n{void*}
type for send and receive buffers. In Fortran this is solved by having
separate routines for each datatype, and providing an \n{Interface} block
in the MPI module. If you manage to request a version that does not exist,
the compiler will display a message like
\begin{verbatim}
There is no matching specific 
subroutine for this generic subroutine call [MPI_Send]
\end{verbatim}

\Level 2 {Byte calculations}
\label{sec:f-sizeof}

Fortran lacks a \n{sizeof} operator to query the sizes of datatypes.
Since sometimes exact byte counts are necessary,
for instance in one-sided communication,
Fortran can use the \indexmpishow{MPI_Sizeof} routine,
for instance for \indexmpishow{MPI_Win_create}:
\begin{verbatim}
call MPI_Sizeof(windowdata,window_element_size,ierr)
window_size = window_element_size*500
call MPI_Win_create( windowdata,window_size,window_element_size,... );
\end{verbatim}

\index{MPI!Fortran issues|)}

\Level 1 {Python issues}
\label{sec:python-stuff}
\index{MPI!Python issues|(}

\Level 2 {Byte calculations}

The \indexmpishow{MPI_Win_create} routine needs a displacement in
bytes. Here is a good way for finding the size of \indexterm{numpy} datatypes:
\begin{verbatim}
numpy.dtype('i').itemsize
\end{verbatim}

\Level 2 {Arrays of objects}

Objects of type \n{MPI.Status} or \n{MPI.Request} often need to be created
in an array, for instance when looping through a number of \n{Isend} calls.
In that case the following idiom may come in handy:
\begin{verbatim}
requests = [ None ] * nprocs
for p in range(nprocs):
  requests[p] = comm.Irecv( ... )
\end{verbatim}

\index{MPI!Python issues|)}

\Level 1 {Cancelling messages}

In section~\ref{sec:mpi-source} we showed a master-worker example where the 
master accepts in arbitrary order the messages from the workers.
Here we will show a slightly
more complicated example, where only the result of the first task to
complete is needed. Thus, we issue an \n{MPI_Recv}
with \indexmpishow{MPI_ANY_SOURCE} as source.  When a result comes, we
broadcast its source to all processes.  All the other workers then use
this information to cancel their message with
an \indexmpishow{MPI_Cancel} operation.

\verbatimsnippet{cancel}

\Level 1 {Constants}

MPI constants such as \n{MPI_COMM_WORLD} or \n{MPI_INT} are not
necessarily statitally defined, such as by a \n{#define} statement:
the best you can say is that they have a value after
\indexmpishow{MPI_Init} or \indexmpishow{MPI_Init_thread}.
That means you can not transfer a compiled MPI file between
platforms, or even between compilers on one platform.
However, a working MPI source on one MPI implementation
will also work on another.

\Level 0 {Context information}
\label{sec:context}

\Level 1 {Processor name}

You can query the \indexterm{hostname} of a processor.
This name need not be unique between different processor ranks.
%
\mpiRoutineRef{MPI_Get_processor_name}
%
You have to pass in the character storage:
the character array must be at least \indexmpidef{MPI_MAX_PROCESSOR_NAME} characters long.
The actual length of the name is returned in the \n{resultlen} parameter.

\Level 1 {Version information}

\mpiRoutineRef{MPI_VERSION}

For runtime determination,
%
\mpiRoutineRef{MPI_Get_version}

\Level 1 {Attributes}

\mpiRoutineRef{MPI_Attr_get}

Attributes are:
\begin{itemize}
\item \indexmpishow{MPI_UNIVERSE_SIZE}: the total number of processes
  that can be created. This can be more than the size of
  \n{MPI_COMM_WORLD} if the host list is larger than the number of
  initially started processes. See section~\ref{sec:mpi-dynamic}.
\item \indexmpishow{MPI_APPNUM}: if MPI is used in \ac{MPMD} mode, or
  if \indexmpishow{MPI_Comm_spawn_multiple} is used, this attribute
  reports the how-manieth program we are in.
\end{itemize}

\Level 0 {Timing}
\label{sec:ref:mpi-timing}

MPI has a \indexterm{wall clock} timer: \indexmpishow{MPI_Wtime}
%
\mpiRoutineRef{MPI_Wtime}
%
which gives the number of seconds from a certain point in the past.
(Note the absence of the error parameter in the fortran call.)
\verbatimsnippet{pingpong}

The timer has a resolution of \indexmpishow{MPI_Wtick}:
%
\mpiRoutineRef{MPI_Wtick}

Timing in parallel is a tricky issue. For instance, most clusters do
not have a central clock, so you can not relate start and stop times
on one process to those on another. You can test for a global clock as
follows\indexmpi{MPI_WTIME_IS_GLOBAL}:
\begin{verbatim}
int *v,flag;
MPI_Attr_get( comm, MPI_WTIME_IS_GLOBAL, &v, &flag );
if (mytid==0) printf(``Time synchronized? %d->%d\n'',flag,*v);
\end{verbatim}
%\indexmpi{MPI_Wtime} can be either a function or a macro.

%\Level 1 {Profiling}
%\label{sec:ref:profile}

\Level 0 {Multi-threading}
\label{sec:ref:mpi-thread}

Hybrid MPI/threaded codes need to replace \indexmpishow{MPI_Init}
by \n{MPI_Init_thread}:
%
\mpiRoutineRef{MPI_Init_thread}
%
With the \n{required} parameter the user requests a certain level of support,
and MPI reports the actual capabilities in the \n{provided} parameter.

The following constants are defined:
\begin{itemize}
\item \indexmpishow{MPI_THREAD_SINGLE}: each MPI process can only have
  a single thread.
\item \indexmpishow{MPI_THREAD_FUNNELED}: an MPI process can be
  multithreaded, but all MPI calls need to be done from a single
  thread.
\item \indexmpishow{MPI_THREAD_SERIALIZED}: a processes can sustain
  multiple threads that make MPI calls, but these threads can not be
  simultaneous: they need to be for instance in an OpenMP
  \indexterm{critical section}.
\item \indexmpishow{MPI_THREAD_MULTIPLE}: processes can be fully
  generally multi-threaded.
\end{itemize}
These values are monotonically increasing.

After the initialization call, you can query the support level
with \n{MPI_Query_thread}:
%
\mpiRoutineRef{MPI_Query_thread}

In case more than one thread performs communication, the following routine
can determine whether a thread is the main thread:
%
\mpiRoutineRef{MPI_Is_thread_main}
