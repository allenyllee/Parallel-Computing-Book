% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2012-9
%%%%
%%%% mpiref.tex : MPI reference
%%%% this file should be abandoned.
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section gives reference information and illustrative examples
of the use of MPI. While the code snippets given here should be enough,
full programs can be found in the repository for this book
\url{https://bitbucket.org/VictorEijkhout/parallel-computing-book}.

\Level 0 {Elementary datatypes}
\label{sec:datatype-list}

List of predefined \indexmpidef{MPI_Datatype} values:

\begin{tabular}{|l|l|l|}
  \hline
  C&Fortran&meaning\\
  \hline
  \n{MPI_CHAR}&  \n{MPI_CHARACTER}&\\
  \n{MPI_SHORT}&  \n{MPI_BYTE}&\\
  \n{MPI_INT}&  \n{MPI_INTEGER}&\\
  \n{MPI_LONG}&\\
  \n{MPI_UNSIGNED_CHAR}&\\
  \n{MPI_UNSIGNED_SHORT}&\\
  \n{MPI_UNSIGNED}&\\
  \n{MPI_UNSIGNED_LONG}&\\
  \n{MPI_FLOAT}&  \n{MPI_REAL}&\\
  \n{MPI_DOUBLE}&  \n{MPI_DOUBLE_PRECISION}&\\
  \n{MPI_LONG_DOUBLE}&\\
  \n{MPI_BYTE}&\\
  \n{MPI_PACKED}&  \n{MPI_PACKED}&\\
  &\n{MPI_COMPLEX}&\\
  &\n{MPI_DOUBLE_COMPLEX}&\\
  &\n{MPI_LOGICAL}&\\  
  \hline
  &&optional\\
  \hline
  \n{MPI_LONG_LONG_INT}&\\
  &\n{MPI_INTEGER1}&\\
  &\n{MPI_INTEGER2}&\\
  &\n{MPI_INTEGER4}&\\
  &\n{MPI_REAL2}&\\
  &\n{MPI_REAL4}&\\
  &\n{MPI_REAL8}&\\
  \hline
\end{tabular}

\Level 0 {Communicators}

\Level 1 {Process topologies}
\label{sec:ref:topology}

\Level 2 {Cartesian grid topology}
\label{sec:ref:cartesian}

\Level 0 {Leftover topics}

\Level 1 {MPI constants}
\index{MPI!constants|(}

MPI has a number of built-in \emph{constants}. These do not all behave
the same.
\begin{itemize}
\item Some are \emph{compile-time}\index{MPI!constants!compile-time}
  constants. Examples are \indexmpishow{MPI_VERSION} and
  \indexmpishow{MPI_MAX_PROCESSOR_NAME}. Thus, they can be used in
  array size declarations, even before \indexmpishow{MPI_Init}.
\item Some \emph{link-time}\index{MPI!constants!link-time}
  constants get their value by MPI initialization, such as
  \indexmpishow{MPI_COMM_WORLD}. Such symbols, which include all
  predefined handles, can be used in initialization expressions.
\item Some link-time symbols can not be used in initialization
  expressions, such as \indexmpishow{MPI_BOTTOM} and \indexmpishow{MPI_STATUS_IGNORE}.
\end{itemize}

For symbols, the binary realization is not defined. For instance,
\indexmpishow{MPI_COMM_WORLD} is of type \indexmpishow{MPI_Comm}, but
the implementation of that type is not specified.

See Annex~A of the 3.1 standard for full lists.

The following are the compile-time constants:
\begin{lstlisting}
MPI_MAX_PROCESSOR_NAME
MPI_MAX_LIBRARY_VERSION_STRING
MPI_MAX_ERROR_STRING
MPI_MAX_DATAREP_STRING
MPI_MAX_INFO_KEY
MPI_MAX_INFO_VAL
MPI_MAX_OBJECT_NAME
MPI_MAX_PORT_NAME
MPI_VERSION
MPI_SUBVERSION
MPI_STATUS_SIZE (Fortran only)
MPI_ADDRESS_KIND (Fortran only)
MPI_COUNT_KIND (Fortran only)
MPI_INTEGER_KIND (Fortran only)
MPI_OFFSET_KIND (Fortran only)
MPI_SUBARRAYS_SUPPORTED (Fortran only)
MPI_ASYNC_PROTECTS_NONBLOCKING (Fortran only)
\end{lstlisting}

The following are the link-time constants:
\begin{lstlisting}
MPI_BOTTOM
MPI_STATUS_IGNORE
MPI_STATUSES_IGNORE
MPI_ERRCODES_IGNORE
MPI_IN_PLACE
MPI_ARGV_NULL
MPI_ARGVS_NULL
MPI_UNWEIGHTED
MPI_WEIGHTS_EMPTY
\end{lstlisting}

Assorted constants:
\begin{lstlisting}
C type: const int (or unnamed enum)
Fortran type: INTEGER

MPI_PROC_NULL
MPI_ANY_SOURCE
MPI_ANY_TAG
MPI_UNDEFINED
MPI_BSEND_OVERHEAD
MPI_KEYVAL_INVALID                
MPI_LOCK_EXCLUSIVE
MPI_LOCK_SHARED
MPI_ROOT
\end{lstlisting}

(This section was inspired by
\url{http://blogs.cisco.com/performance/mpi-outside-of-c-and-fortran}.)

\index{MPI!constants|)}

\Level 1 {32-bit size issues}

The \n{size} parameter in MPI routines is defined as an \n{int},
meaning that it is limited to 32-bit quantities.  There are ways
around this, such as sending a number of
\indexmpishow{MPI_Type_contiguous} blocks that add up to more than~$2^{31}$.

\Level 1 {Fortran issues}
\label{sec:ref:mpi-fortran}
\index{MPI!Fortran issues|(}

\Level 2 {Data types}

The equivalent of \indexmpishowsub{MPI_Aint}{in Fortran} is
\lstset{language=Fortran} %pyskip
\begin{lstlisting}
integer(kind=MPI_ADDRESS_KIND) :: winsize
\end{lstlisting}

\Level 2 {Type issues}

Fortran90 is a strongly typed language, so it is not possible to pass
argument by reference to their address, as C/C++ do with the \n{void*}
type for send and receive buffers. In Fortran this is solved by having
separate routines for each datatype, and providing an \n{Interface} block
in the MPI module. If you manage to request a version that does not exist,
the compiler will display a message like
\begin{verbatim}
There is no matching specific 
subroutine for this generic subroutine call [MPI_Send]
\end{verbatim}

\Level 2 {Byte calculations}
\label{sec:f-sizeof}

Fortran lacks a \n{sizeof} operator to query the sizes of datatypes.
Since sometimes exact byte counts are necessary,
for instance in one-sided communication,
Fortran can use the \indexmpishow{MPI_Sizeof} routine.

\mpiRoutineRef{MPI_Sizeof}

Example usage in \indexmpishow{MPI_Win_create}:
\begin{lstlisting}
call MPI_Sizeof(windowdata,window_element_size,ierr)
window_size = window_element_size*500
call MPI_Win_create( windowdata,window_size,window_element_size,... );
\end{lstlisting}
\lstset{language=C} %pyskip

This routine is deprecated in \indexterm{MPI-4}: use of
\indextermtt{storage_size} and/or \indextermtt{c_sizeof} is recommended.

\index{MPI!Fortran issues|)}

\Level 0 {Timing}
\label{sec:ref:mpi-timing}

MPI has a \indexterm{wall clock} timer: \indexmpishow{MPI_Wtime}
%
\mpiRoutineRef{MPI_Wtime}
%
which gives the number of seconds from a certain point in the past.
(Note the absence of the error parameter in the fortran call.)
\cverbatimsnippet{pingpong}

The timer has a resolution of \indexmpishow{MPI_Wtick}:
%
\mpiRoutineRef{MPI_Wtick}

Timing in parallel is a tricky issue. For instance, most clusters do
not have a central clock, so you can not relate start and stop times
on one process to those on another. You can test for a global clock as
follows\indexmpi{MPI_WTIME_IS_GLOBAL}:
\begin{lstlisting}
int *v,flag;
MPI_Attr_get( comm, MPI_WTIME_IS_GLOBAL, &v, &flag );
if (mytid==0) printf(``Time synchronized? %d->%d\n'',flag,*v);
\end{lstlisting}
%\indexmpi{MPI_Wtime} can be either a function or a macro.

%\Level 1 {Profiling}
%\label{sec:ref:profile}

