% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Computing'
%%%% by Victor Eijkhout, copyright 2012-6
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section gives reference information and illustrative examples
of the use of OpenMP. While the code snippets given here should be enough,
full programs can be found in the repository for this book
\url{https://bitbucket.org/VictorEijkhout/parallel-computing-book}.

The definitive information on OpenMP can be found on
\url{http://openmp.org/}; more tutorials can be found at
\url{http://openmp.org/wp/resources/} where the one
by Tim Mattson is particularly recommended.

\Level 0 {Reference stuff}

\Level 0 {Controlling thread data}

\Level 1 {Shared data}

Data that existed in the master thread of a team
is shared between the team. This is default behaviour.
The clause \indexclause{shared} can be used for completeness,
for instance if \n{default(none)} is declared.

While shared data is readable and writable by every thread, their view
of data may not always be consistent. Therefore, reads should be
preceded by a \indexpragma{flush} command.  Fortunately, in many cases
this is done by default; see section~\ref{ref:omp:flush}.

\Level 1 {Private data}
\commandreflabel{omp-private}

Data that is declared private with the \indexpragma{private} directive is
put on a separate \indextermbus{stack}{per thread}. The OpenMP standard
does not dictate the size of these stacks, but beware of \indextermbus{stack}{overflow}.
A~typical default
is a few megabyte; you can control it with the environment variable
\indextermtt{OMP_STACKSIZE}. Its values can be literal or with suffixes:
\begin{verbatim}
123 456k 567K 678m 789M 246g 357G
\end{verbatim}

A normal \indextermbus{Unix}{process} also has a stack, but this is
independent of the OpenMP stacks for private data. You can query or
set the Unix stack with \indextermtt{ulimit}:
\begin{verbatim}
[] ulimit -s
64000
[] ulimit -s 8192
[] ulimit -s
8192
\end{verbatim}
The Unix stack can grow dynamically as space is needed. This does not
hold for the OpenMP stacks: they are immediately allocated at their
requested size. Thus it is important not too make them too large.

\Level 1 {Data in dynamic scope}

Functions that are called from a parallel region fall in the
\emph{dynamic scope}\index{parallel region!dynamic scope} of that
parallel region. The rules for variables in that function are as follows:
\begin{itemize}
\item Any variables locally defined to the function are private.
\item \n{static} variables in C and \n{save} variables in Fortran
  are shared.
\item The function arguments inherit their status from the calling environment.
\end{itemize}

\Level 0 {Synchronization}

\Level 1 {Critical sections}
\commandreflabel{critical}

The pragmas \indexpragmadef{critical} and \indexpragmadef{atomic}
are two ways to indicate that a section of code can only be executed
by one thread at a time.

\begin{verbatim}
#pragma omp critical [(name)] new-line
    structured-block
\end{verbatim}

Not required to be in a parallel region?

\Level 1 {Locks}
\label{ompref:locks}

Create/destroy:
\begin{verbatim}
void omp_init_lock(omp_lock_t *lock);
void omp_destroy_lock(omp_lock_t *lock);
\end{verbatim}
Set and release:
\begin{verbatim}
void omp_set_lock(omp_lock_t *lock);
void omp_unset_lock(omp_lock_t *lock);
\end{verbatim}
Since the set call is blocking, there is also 
\begin{verbatim}
omp_test_lock();
\end{verbatim}

Unsetting a lock needs to be done by the thread that set it.

Lock operations implicitly have a \n{flush}.

\Level 0 {Internal control variables}
\label{ref:omp-environ}
\index{OpenMP!environment variables|(textbf}
\index{OpenMP!library routines|(textbf}
\index{Internal Control Variable (ICV)|(textbf}

OpenMP has a number of settings that can be set through \emph{environment variables},
and both queried and set through \emph{library routines}. These settings are called
\emph{\acfp{ICV}}: an OpenMP implementation behaves as if there is an internal variable
storing this setting.

First, there are 4 \acp{ICV} that behave as if each thread has its own copy of them.
The default is implementation-defined unless otherwise noted.
\begin{itemize}
  \item It may be possible to adjust dynamically the number of threads
    for a parallel region. Variable: \indextermtt{OMP_DYNAMIC};
    routines: \indextermtt{omp_set_dynamic},
    \indextermtt{omp_get_dynamic}.
  \item If a code contains \indextermsub{nested}{parallel regions},
    the inner regions may create new teams, or they may be executed by
    the single thread that encounters them. Variable:
    \indextermtt{OMP_NESTED}; routines \indextermtt{omp_set_nested},
    \indextermtt{omp_get_nested}. Allowed values are \n{TRUE} and
    \n{FALSE}; the default is false.
  \item The number of threads used for an encountered parallel region
    can be controlled. Variable: \indextermtt{OMP_NUM_THREADS};
    routines \indextermtt{omp_set_num_threads},
    \indextermtt{omp_get_max_threads}.
  \item The schedule for a parallel loop can be set. Variable:
    \indextermtt{OMP_SCHEDULE}; routines
    \indextermtt{omp_set_schedule}, \indextermtt{omp_get_schedule}.
\end{itemize}

Non-obvious syntax:
\begin{verbatim}
export OMP_SCHEDULE="static,100"
\end{verbatim}

Other settings:
\begin{itemize}
\item\indextermtt{omp_get_num_threads}: query the number of threads
  active at the current place in the code; this can be lower than what
  was set with \n{omp_set_num_threads}. For a meaningful answer, this
  should be done in a parallel region.
\item\indextermtt{omp_get_thread_num}
\item\indextermtt{omp_in_parallel}: test if you are in a parallel
  region (see for instance section~\ref{sec:parallelregion}).
\item\indextermtt{omp_get_num_procs}: query the physical number of cores available.
\end{itemize}

Other environment variables:
\begin{itemize}
\item \indextermtt{OMP_STACKSIZE} controls the amount of space that is
  allocated as per-thread \indexterm{stack}; the space for private
  variables.
\item \indextermtt{OMP_WAIT_POLICY} determines the behaviour of
  threads that wait, for instance for \indexterm{critical section}:
  \begin{itemize}
  \item \n{ACTIVE} puts the thread in a \indexterm{spin-lock}, where
    it actively checks whether it can continue;
  \item \n{PASSIVE} puts the thread to sleep until the \ac{OS} wakes
    it up.
  \end{itemize}
  The `active' strategy uses CPU while the thread is waiting; on the
  other hand, activating it after the wait is instantaneous. With the
  `passive' strategy, the thread does not use any CPU while waiting,
  but activating it again is expensive. Thus, the passive strategy
  only makes sense if threads will be waiting for a (relatively) long
  time.
\item \indextermtt{OMP_PROC_BIND} with values \n{TRUE} and \n{FALSE}
  can bind threads to a processor. On the one hand, doing so can
  minimize data movement; on the other hand, it may increase load
  imbalance.
\end{itemize}

\index{OpenMP!environment variables|)}
\index{OpenMP!library routines|)}
\index{Internal Control Variable (ICV)|)}

\Level 0 {Stuff}

\Level 1 {Timing}
\commandreflabel{omp-timing}

To do \indextermsub{OpenMP}{timing} you can use any system utility;
however there is a dedicated routine \indexcommand{omp_get_wtime}
that express the time since some starting point as a double:
\begin{verbatim}
double omp_get_wtime(void);
\end{verbatim}
The starting point is arbitrary and is different for each program run;
however, in one run it is identical for all threads.

To measure a time difference:
\begin{verbatim}
double tstart,tend,duration;
tstart = omp_get_wtime();
// do stuff
tend = omp_get_wtime();
duration = tend-tstart;
\end{verbatim}
The timer resolution is given by:
\begin{verbatim}
double omp_get_wtick(void);
\end{verbatim}

\Level 1 {Affinity}

For performance it can be a good idea to bind threads to specific
processors or cores.  OpenMP (as of \emph{version 3.1}) has a
mechanism for \indextermbus{thread}{affinity}\index{OpenMP!version 3.1!thread
  affinity}:\indextermtt{OMP_PROC_BIND}
\begin{verbatim}
export OMP_PROC_BIND=true  
\end{verbatim}
Apart from this, compilers can have proprietary mechanism; 
e.g., for the intel compiler the variable is
\begin{verbatim}
export KMP_AFFINITY=compact,0
\end{verbatim}
for the sun compiler:
\begin{verbatim}
export SUNW_MP_PROCBIND=TRUE
\end{verbatim}
for gcc (pre-openmp 3.1)
\begin{verbatim}
export GOMP_CPU_AFFINITY=0-63
\end{verbatim}

\Level 1 {Relaxed memory model}
\commandreflabel{omp:flush}

\indexpragma{flush}

\begin{itemize}
\item There is an implicit flush of all variables at the start and end 
  of a \emph{parallel region}\index{parallel region!flush at}.
\item There is a flush at each barrier, whether explicit or implicit,
  such as at the end of a \emph{work sharing}\index{workshare
    !flush after}.
\item At entry and exit of a \emph{critical section}\index{critical
  section!flush at}
\item When a \emph{lock}\index{lock!flush at} is set or unset.
\end{itemize}

