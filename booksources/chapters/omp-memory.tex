% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2012-6
%%%%
%%%% omp-memory.tex : OpenMP memory model
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Level 0 {Thread synchronization}

Let's do a \indexterm{producer-consumer} model\footnote{This example
  is from Intel's excellent OMP course by Tim Mattson}.  This can be
implemented with sections, where one section, the producer, sets a
flag when data is available, and the other, the consumer, waits until
the flag is set.
\begin{verbatim}
#pragma omp parallel sections
{
  // the producer
  #pragma omp section
  {
    ... do some producing work ...
    flag = 1;
  }
  // the consumer
  #pragma omp section
  {
    while (flag==0) { }
    ... do some consuming work ...
  }
}
\end{verbatim}
One reason this doesn't work, is that the compiler will see that the flag is never used
in the producing section, and that is never changed in the consuming section, so
it may optimize these statements, to the point of optimizing them away.

The producer then needs to do:
\begin{verbatim}
... do some producing work ...
#pragma omp flush
#pragma atomic write
  flag = 1;
#pragma omp flush(flag)
\end{verbatim}
and the consumer does:
\begin{verbatim}
#pragma omp flush(flag)
while (flag==0) {
  #pragma omp flush(flag)
}
#pragma omp flush
\end{verbatim}
This code strictly speaking has a \indexterm{race condition} on the \n{flag} variable.
It is better to use an \indexpragma{atomic} pragma here: the producer has
\begin{verbatim}
#pragma atomic write
  flag = 1;
\end{verbatim}
and the consumer:
\begin{verbatim}
while (1) {
  #pragma omp flush(flag)
  #pragma omp atomic read
    flag_read = flag
  if (flag_read==1) break;
}
\end{verbatim}

\Level 0 {Data races}
\index{data race|see{race condition}}
\index{race condition!in OpenMP|(}

OpenMP, being based on shared memory, has a potential for \emph{race
  conditions}. These happen when two threads access the same data
item. The problem with race conditions is that programmer convenience
runs counter to efficient execution. For this reason, OpenMP simply
does not allow some things that would be desirable.

The basic rule about multiple-thread access of a single data item is:
\begin{quote}
  Any memory location that is \emph{written} by one thread, can not be
  \emph{read} by another thread in the same parallel region, if no
  synchronization is done.
\end{quote}
To start with that last clause: any workshare construct ends with an
\indextermsub{implicit}{barrier}, so data written before that barrier
can safely be read after it.

As an illustration of a possible problem:
\begin{verbatim}
c = d = 0;
#pragma omp sections
{
#pragma omp section
  { a = 1; c = b; }
#pragma omp section
  { b = 1; d = a; }
}
\end{verbatim}
Under any reasonable interpretation of parallel execution,
the possible values for \n{c,d} are $1,1$ $0,1$ or~$1,0$.
This is known as \indexterm{sequential consistency}:
the parallel outcome is consistent with a sequential execution that
interleaves the parallel computations, respecting their local statement orderings.
(See also~\HPSCref{sec:seq-consist}.)

However, without synchronization, threads are allowed to maintain a value for a
variable locally that is not the same as the stored value. In this
example, that means that the thread executing the first section need
not write its value of~\n{a} to memory, and likewise \n{b}~in the
second thread, so $0,0$~is in fact a possible outcome.

In order to resolve multiple accesses:
\begin{enumerate}
\item Thread one reads the variable.
\item Thread one flushes the variable.
\item Thread two flushes the variable.
\item Thread two reads the variable.
\end{enumerate}

% \url{https://software.intel.com/es-es/forums/intel-moderncode-for-parallel-architectures/topic/610017}

\index{race condition!in OpenMP|)}
  
\Level 0 {Relaxed memory model}
\label{sec:omp:flush}

\indexpragma{flush}

\begin{itemize}
\item There is an implicit flush of all variables at the start and end 
  of a \emph{parallel region}\index{parallel region!flush at}.
\item There is a flush at each barrier, whether explicit or implicit,
  such as at the end of a \emph{work sharing}\index{workshare
    !flush after}.
\item At entry and exit of a \emph{critical section}\index{critical
  section!flush at}
\item When a \emph{lock}\index{lock!flush at} is set or unset.
\end{itemize}

